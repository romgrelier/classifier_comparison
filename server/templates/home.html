{% extends "layout.html" %}

{% block navbar %}
<a class="nav-item nav-link active" href="/">Accueil</a>
<a class="nav-item nav-link" href="/data">Données</a>
<a class="nav-item nav-link" href="/tree">Arbre</a>
<a class="nav-item nav-link" href="/resultat">Resultats</a>
{% endblock %}

{% block body %}

<div class="jumbotron jumbotron-fluid">
    <div class="container">
        <h1 class="display-4">Comparaison de classifieurs</h1>
    </div>
</div>

<div class="jumbotron">
    <h3>Introduction</h3>
    <p>
        Cette interface web permet la comparaison de plusieurs algorithmes de classification avec différents datasets.
        Nous avons utilisé scikit-learn pour la cross validation et la création d'arbre de dicision, random forest et K-NN, avec les paramêtres par défault.
        Plusieurs module dont pandas et matpotlib pour l'affichage des valeur.  
    </p>

    <h3>Datasets</h3>
    <p>Quatre jeux de données sont proposés :</p>

    <ul>
        <il><strong>optdigits</strong> : chiffres écrits de manière manuscrite par des personnes différentes, c'est un
            problème de reconnaissance de chiffres via des matrices représentant les différentes images.</il><br />
        <il><strong>iris</strong> : problème de reconnaissance d'iris à partir des caractéristiques de leurs pétales
        </il><br />
        <il><strong>mushroom</strong> : déterminer si un champignon est vénéneux</il><br />
        <il><strong>krkop</strong> (King-Rook vs. King) : resultat d'une partie d'echec avec un nombre limité de pièces</il><br />
    </ul>

    <p>
        Les quatre datasets sont téléchargés directement depuis le site de l'uci, qui sont par la suite normalisés avant
        d'être utilisés pour la classification.
    </p>

    <h3>Méthodes utilisée</h3>
    <p>
        Nous utilisons 3 algorithmes de classification :
    </p>

    <ul>
        <li><strong>Arbre de décision</strong> : Le nombre d'exemple par feuille est paramètrable avec un nombre N
        </li><br />
        <li><strong>Random Forest</strong> : comme pour l'arbre de décision le nombre d'exemple minimum avec
            N</li><br />
        <li><strong>KNN</strong> : ici N donne le nombre de voisin</li><br />
    </ul>

    <p>
        Pour chaque algorithme est appliqué la cross validation en faisant varier leur paramètre N, puis est conservé le meilleur paramètre.
    </p>

    <h3>Resultats</h3>
    <p>
        Ici l'accent est mis sur l'arbre de décision, il est donc possible de choisir le dataset, la classe à prédire.
        Une fois ces paramètres renseignés la cross validation est appliquée, puis le meilleur paramètre conservé génère un nouveau modèle dont l'arbre est affiché dans l'onglet "Données".
        Les résultats de la cross validation se situent dans l'onglet "Resultats" où est affiché en fonction du nombre N de l'algorithme. (Peut prendre du temps)
    </p>
</div>

{% endblock %}